# Taming-Big-Data-with-Apache-Spark-and-Python

- Learn the concepts of Spark's DataFrames and Resilient Distributed Datastores
- Develop and run Spark jobs quickly using Python
- Translate complex analysis problems into iterative or multi-stage Spark scripts
- Scale up to larger data sets using Amazon's Elastic MapReduce service
- Understand how Hadoop YARN distributes Spark across computing clusters
- Learn about other Spark technologies, like Spark SQL, Spark Streaming, and GraphX

[Taming Big Data with Apache Spark and Python - Hands On!](https://www.udemy.com/course/taming-big-data-with-apache-spark-hands-on/)
